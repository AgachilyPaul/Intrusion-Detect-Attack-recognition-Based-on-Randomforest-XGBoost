{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Data Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sklearn\n!pip install xgboost\n!pip install lightgbm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Library Description\nAxes3D: 绘制3D图形  \nStandarScaler: 用于归一化处理  \nSelectFromModel: 特征选择  \nGridSearchCV: 网格搜索\njoblib: 用于保存模型  \npreprocessing: 用于数据预处理  \nConsult: https://blog.csdn.net/weixin_40807247/article/details/82793220","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt \nimport numpy as np \nimport os \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn import preprocessing\nfrom sklearn.externals import joblib\nfrom matplotlib.pyplot import plot\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Description","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 对数据的41项特征进行命名,最后一项attack类型单独处理\ncols = \"\"\"\nduration,\nprotocol_type,\nservice,\nflag,\nsrc_bytes,\ndst_bytes,\nland,\nwrong_fragment,\nurgent,\nhot,\nnum_failed_logins,\nlogged_in,\nnum_compromised,\nroot_shell,\nsu_attempted,\nnum_root,\nnum_file_creations,\nnum_shells,\nnum_access_files,\nnum_outbound_cmds,\nis_host_login,\nis_guest_login,\ncount,\nsrv_count,\nserror_rate,\nsrv_serror_rate,\nrerror_rate,\nsrv_rerror_rate,\nsame_srv_rate,\ndiff_srv_rate,\nsrv_diff_host_rate,\ndst_host_count,\ndst_host_srv_count,\ndst_host_same_srv_rate,\ndst_host_diff_srv_rate,\ndst_host_same_src_port_rate,\ndst_host_srv_diff_host_rate,\ndst_host_serror_rate,\ndst_host_srv_serror_rate,\ndst_host_rerror_rate,\ndst_host_srv_rerror_rate\"\"\"\ncols = [c.strip() for c in cols.split(\",\") if c.strip()]\n# 对最后一列单独加上target标签\ncols.append('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 将源数据中标签对应的攻击类型进行归类\nattacks_type = {\n'normal': 'normal',\n'back': 'dos',\n'buffer_overflow': 'u2r',\n'ftp_write': 'r2l',\n'guess_passwd': 'r2l',\n'imap': 'r2l',\n'ipsweep': 'probe',\n'land': 'dos',\n'loadmodule': 'u2r',\n'multihop': 'r2l',\n'neptune': 'dos',\n'nmap': 'probe',\n'perl': 'u2r',\n'phf': 'r2l',\n'pod': 'dos',\n'portsweep': 'probe',\n'rootkit': 'u2r',\n'satan': 'probe',\n'smurf': 'dos',\n'spy': 'r2l',\n'teardrop': 'dos',\n'warezclient': 'r2l',\n'warezmaster': 'r2l',\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 读入数据\ndf = pd.read_csv(\"../input/kdd-cup-1999-data/kddcup.data_10_percent/kddcup.data_10_percent\", names=cols)\n# 将整理后的攻击类型放入Attack列中\ndf['Attack'] = df.target.apply(lambda r: attacks_type[r[:-1]])\nprint(\"The data shape is (lines, columns):\",df.shape)\n# df['service'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 重命名名称\nhajar_to_cup = {\n'is_hot_login' : 'is_host_login',\n'urg' : 'urgent',\n'protocol' : 'protocol_type',\n'count_sec' : 'count',\n'srv_count_sec' : 'srv_count',\n'serror_rate_sec' : 'serror_rate',\n'srv_serror_rate_sec' : 'srv_serror_rate',\n'rerror_rate_sec' : 'rerror_rate',\n'srv_error_rate_sec' : 'srv_rerror_rate',\n'same_srv_rate_sec' : 'same_srv_rate',\n'diff_srv_rate_sec' : 'diff_srv_rate',\n'srv_diff_host_rate_sec' : 'srv_diff_host_rate',\n'count_100' : 'dst_host_count',\n'srv_count_100' : 'dst_host_srv_count',\n'same_srv_rate_100' : 'dst_host_same_srv_rate',\n'diff_srv_rate_100' : 'dst_host_diff_srv_rate',\n'same_src_port_rate_100' : 'dst_host_same_src_port_rate',\n'srv_diff_host_rate_100' : 'dst_host_srv_diff_host_rate',\n'serror_rate_100' : 'dst_host_serror_rate',\n'srv_serror_rate_100' : 'dst_host_srv_serror_rate',\n'rerror_rate_100' : 'dst_host_rerror_rate',\n'srv_rerror_rate_100' : 'dst_host_srv_rerror_rate',\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#不同攻击类型的记录数量统计\ndf.Attack.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#标签、攻击的种类\ndf.target.unique(), df.Attack.unique()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 绘制相关矩阵\ndef plotCorrelationMatrix(df, graphWidth, dataframeName):\n    filename = dataframeName\n    df = df.dropna('columns') # 舍去值为NaN的列\n    df = df[[col for col in df if df[col].nunique() > 1]] # 保留拥有多于一个唯一值的列\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    # 获取数据之间的相关系数\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    # 对x,y轴进行设置\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    # 配色\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 绘制分布直方图\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 70]]\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (8 * nGraphPerRow, 10 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observe the distribution characteristics of data\n(观察数据分布特征)  \nConsult the blog https://blog.csdn.net/Eastmount/article/details/103189405, we draw the histograms of blew features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plotPerColumnDistribution(df[[\n    'protocol_type',\n    'service',\n    'flag',\n    'logged_in',\n    'srv_serror_rate',\n    'srv_diff_host_rate',\n]], nGraphShown=30, nGraphPerRow=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can find that ICMP protocol is the most used one among the these protocols, followed by TCP protocol and about 20000 packets of UDP protocol. In addition, only 70000 packets successfully logged in.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The correlation among data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 查看数据之间的相关度\nplotCorrelationMatrix(df, graphWidth=20, dataframeName=\"Packets\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#查看是否有缺失值\nfor c in df.columns:\n    print(\"%20s : %d\"%(c, sum(pd.isnull(df[c]))))\n# Reference: https://blog.csdn.net/qq_39072607/article/details/89387907","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 数据标记/编码","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 选取特征（依据方差，相关性）\n* 方差:\n\n方差为0，说明该项特征对于所有记录是一样的，最理想的特征应有较大的方差，说明不同类型的记录在该特征上表现出了差异性。因此移除方差为0的特征。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_std = df.std() #所有特征的方差\ndf_std = df_std.sort_values(ascending=True) #排序输出\ndf_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.plot(list(df_std.index) ,list(df_std.values), 'go')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 相关性:\n\n可以消除一些完全相关的特征。如（srv_serror_rate，serror_rate）与（dst_host_srv_count，dst_host_count）相关，则在这种情况下，可以消除srv_rate和dst_host_count。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 通过plotScatterMatrix观察相关矩阵\ndef standardize_columns(df, cols_map=hajar_to_cup):\n    #删除'service'列；如果存在TCPDUMP列则重命名\n    if 'service' in df.columns:\n        df = df.drop(['service'], axis = 1)\n    df.rename(columns = cols_map)\n    return df\n\ndf = standardize_columns(df, cols_map=hajar_to_cup)\n#df = df.drop(['is_host_login','num_outbound_cmds','dst_host_count','srv_serror_rate'], axis = 1)\n#df.head(10)\ndf.columns.values \n# Reference：https://blog.csdn.net/u010652755/article/details/105612332","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 将数据分为训练集和测试集","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['target',], axis=1)\nprint(df.shape)\n#以前41项作为输入X，Attack列作为检测标签y\ny = df.Attack\nX = df.drop(['Attack',], axis=1)\n#随机生成训练集、测试集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nprint(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"le_X_cols = {}\nle_y = preprocessing.LabelEncoder()\n\nfor c in X_train.columns:\n    if str(X_train[c].dtype) == 'object': \n        le_X = preprocessing.LabelEncoder()\n        X_train[c] = le_X.fit_transform(X_train[c])\n        X_test[c] = le_X.transform(X_test[c])\n        le_X_cols[c] = le_X\n\ny_train = le_y.fit_transform(y_train.values)\ny_test = le_y.transform(y_test.values)\n\n#保存标签\njoblib.dump(le_X_cols, 'le_X_cols.pkl') \njoblib.dump(le_y, 'le_y.pkl') \n# Reference: https://www.cnblogs.com/caimuqing/p/9074046.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names, class_index = le_y.classes_, np.unique(y_train)\nclass_names, class_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#特征缩放\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX_train[['dst_bytes','src_bytes']] = scaler.fit_transform(X_train[['dst_bytes','src_bytes']])\nX_test[['dst_bytes','src_bytes']] = scaler.transform(X_test[['dst_bytes','src_bytes']])\n#保存\njoblib.dump(scaler, 'scaler_1.pkl') \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 两种分模型（随机森林和XGBoost）","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1- 随机森林分类模型","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#没有参数调整和特征选择的基础模型\nclassifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 42)\nclassifier.fit(X_train, y_train)\nprint(\"训练准确度:\", classifier.score(X_train, y_train))\nprint(\"测试准确度:\",classifier.score(X_test,y_test))\ndiff_base = abs(classifier.score(X_train, y_train) - classifier.score(X_test,y_test))\nprint(\"模型的过度/不足拟合：\", diff_base)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#预测测试集中的数据\ny_pred = classifier.predict(X_test)\n\nreversefactor = dict(zip(class_index,class_names))\ny_test_rev = np.vectorize(reversefactor.get)(y_test)\ny_pred_rev = np.vectorize(reversefactor.get)(y_pred)\n#生成混淆矩阵\nprint(pd.crosstab(y_test_rev, y_pred_rev, rownames=['Actual packets attacks'], colnames=['Predicted packets attcks']))\n\n#fig, ax = plt.subplots(figsize=(15, 10))\n#plot.confusion_matrix(y_test_rev, y_pred_rev, ax=ax)\n#plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1-1 特征选择","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=30)\nclf = clf.fit(X_train, y_train)\nfti = clf.feature_importances_\nmodel = SelectFromModel(clf, prefit=True, threshold= 0.005)\nX_train_new = model.transform(X_train)\nX_test_new = model.transform(X_test)\nselcted_features = X_train.columns[model.get_support()]\nprint(X_train_new.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#选择的特征\nselcted_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1-2参数调整","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'n_estimators'      : [20,40,128,130],\n    'max_depth'         : [None,14, 15, 17],\n    'criterion' :['gini','entropy'],\n    'random_state'      : [42],\n    #'max_features': ['auto'],\n    \n}\nclf = GridSearchCV(RandomForestClassifier(), parameters, cv=2, n_jobs=-1, verbose=5)\nclf.fit(X_train_new, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"clf.best_estimator_:\",clf.best_estimator_)\nprint(\"clf.best_params_\",clf.best_params_)\n#print(\"results:\",clf.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV训练准确率：\",clf.best_score_)\nprint(\"CV测试准确率：\",clf.score(X_test_new,y_test))\ndiff_fst = abs(clf.best_score_ - clf.score(X_test_new,y_test))\nprint(\"准确率差：\", diff_fst)\nprint(\"模型表现提升？\", diff_base > diff_fst)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#混淆矩阵\n#预测测试数据集\ny_pred = clf.predict(X_test_new)\n\nreversefactor = dict(zip(class_index,class_names))\ny_test_rev = np.vectorize(reversefactor.get)(y_test)\ny_pred_rev = np.vectorize(reversefactor.get)(y_pred)\n#生成混淆矩阵\nprint(pd.crosstab(y_test_rev, y_pred_rev, rownames=['Actual packets attacks'], colnames=['Predicted packets attcks']))\n\n#fig, ax = plt.subplots(figsize=(15, 10))\n#plot.confusion_matrix(y_test_rev, y_pred_rev, ax=ax)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 保存模型","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"joblib.dump(clf, 'random_forest_classifier.pkl') \n#To load it: clf_load = joblib.load('saved_model.pkl') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2- XGBoost模型","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2-1基础模型","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import MultiLabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=4, n_estimators=70, random_state=42,verbosity=1))\n\n#通过MultiLabelBinarizer将数组[[x，y，z]]中的变量编码为多标签 \nlb = preprocessing.LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\nlb.fit(y_train)\ny_train_xgb = lb.transform(y_train)\ny_test_xgb = lb.transform(y_test)\n#训练模型\nclf.fit(X_train[selcted_features], y_train_xgb)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#预测\ny_pred_xgb = clf.predict(X_test[selcted_features])\n\nprint(\"训练准确率：\", clf.score(X_train[selcted_features], y_train_xgb))\nprint(\"测试准确率：\",clf.score(X_test[selcted_features],y_test_xgb))# New data, not included in Training data\ndiff_xgb = abs(clf.score(X_train[selcted_features], y_train_xgb) - clf.score(X_test[selcted_features],y_test_xgb))\nprint(\"准确率差：\", diff_xgb)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#混淆矩阵\ny_pred_xgb = np.argmax(y_pred_xgb, axis=1)\n\nreversefactor = dict(zip(class_index,class_names))\ny_test_rev = np.vectorize(reversefactor.get)(y_test)\ny_pred_rev = np.vectorize(reversefactor.get)(y_pred_xgb)\n#生成混淆矩阵\nprint(pd.crosstab(y_test_rev, y_pred_rev, rownames=['Actual packets attacks'], colnames=['Predicted packets attcks']))\n\n\n#fig, ax = plt.subplots(figsize=(15, 10))\n#plot.confusion_matrix(y_test_rev, y_pred_rev, ax=ax)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2-2 参数调整","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nprint(X_train.shape)\n\nxgb_model = OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=4, n_estimators=70, random_state=42,verbosity=1))\n\nparameters = {'estimator__nthread':[4,], #适应线程\n              'estimator__objective':['binary:logistic',],\n              'estimator__learning_rate': [0.1,0.08], #'eta'值\n              'estimator__max_depth': [4,6],\n              'estimator__min_child_weight': [1,],\n              'estimator__silent': [1,],\n              'estimator__subsample': [1,],\n              'estimator__colsample_bytree': [1,],\n              'estimator__n_estimators': [70,100], #决策树的数量\n              'estimator__random_state':[42],\n              }\n\n\nclf = GridSearchCV(xgb_model, parameters, \n                   cv=2, n_jobs=-1, verbose=5, refit=True)\n#训练模型\nclf.fit(X_train[selcted_features], y_train_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV训练准确率：\",clf.best_score_)\nprint(\"参数：\", clf.best_params_)\nprint(\"CV测试准确率：\",clf.score(X_test[selcted_features],y_test_xgb))\ndiff_fst = abs(clf.best_score_ - clf.score(X_test[selcted_features],y_test_xgb))\nprint(\"准确率差：\", diff_fst)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#最佳XGB模型的混淆矩阵\ny_pred_xgb = clf.predict(X_test[selcted_features])\ny_pred_xgb = np.argmax(y_pred_xgb, axis=1)\nreversefactor = dict(zip(class_index,class_names))\ny_test_rev = np.vectorize(reversefactor.get)(y_test)\ny_pred_rev = np.vectorize(reversefactor.get)(y_pred_xgb)\n#生成混淆矩阵\nprint(pd.crosstab(y_test_rev, y_pred_rev, rownames=['Actual packets attacks'], colnames=['Predicted packets attcks']))\n\n#fig, ax = plt.subplots(figsize=(15, 10))\n#plot.confusion_matrix(y_test_rev, y_pred_rev, ax=ax)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 保存模型","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"joblib.dump(clf, 'xgboost_classifier.pkl') \n#加载方法：clf_load = joblib.load('saved_model.pkl') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 组装模型\n#### 根据上述实现的两个模型构建一个模型\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#对应列重命名\nneeded_cols_dump = []\nfor l in selcted_features:\n    if l in hajar_to_cup.values():\n        for k, v in hajar_to_cup.items():\n            if v == l:\n                needed_cols_dump.append(k)\n    else:\n        needed_cols_dump.append(l)\nprint(len(needed_cols_dump), len(selcted_features))\nprint(needed_cols_dump)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_what_we_want(X, \n                    scaler_1, \n                    le_X_cols, \n                    selcted_features, \n                    map_cols,\n                    rdf_clf,\n                    xgb_clf,\n                    PathX=False):\n    if PathX:\n        X = pd.read_csv(PathX, names=cols, nrows=30000)\n    X = standardize_columns(X, cols_map=map_cols) #重命名列\n    X[['dst_bytes','src_bytes']] = scaler_1.fit_transform(X[['dst_bytes','src_bytes']])\n    X = X[selcted_features]\n    for c in X.columns:\n        if str(X[c].dtype) == 'object': \n            le_X = le_X_cols[c]\n            X[c] = le_X.transform(X[c])\n            \n    res = {\n        'rd_prd_prb': rdf_clf.predict_proba(X),\n        'rd_prd': rdf_clf.predict(X),\n        'xgb_prd_prb': xgb_clf.predict_proba(X),\n        'xgb_prd': xgb_clf.predict(X),\n        \n    }\n    \n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_1 = joblib.load('scaler_1.pkl') #缩放后的数据\nle_X_cols = joblib.load('le_X_cols.pkl') #训练集的标签\nle_y = joblib.load('le_y.pkl') #测试集的标签\nxgb_clf = joblib.load('xgboost_classifier.pkl') #XGBoost模型\nrdf_clf = joblib.load('random_forest_classifier.pkl') #随机森林模型","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#读入数据\nX = pd.read_csv(\"../input/kdd-cup-1999-data/kddcup.data_10_percent/kddcup.data_10_percent\", names=cols, nrows=100000)\nY = X.target.apply(lambda r: attacks_type[r[:-1]])\n\nres = do_what_we_want(X, \n                    scaler_1, \n                    le_X_cols, \n                    selcted_features, \n                    hajar_to_cup,\n                    rdf_clf,\n                    xgb_clf,\n                    PathX=False)\nres.keys()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 使用Logistic回归进行汇总以堆叠预测结果","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"atks = ['dos', 'normal', 'probe', 'r2l', 'u2r']\nrd_prd_df = pd.DataFrame(data=res['rd_prd_prb'])\nrd_prd_df= rd_prd_df.rename(columns = {l:'rd_'+atks[l] for l in range(len(atks))})\nxg_prd_df = pd.DataFrame(data=res['xgb_prd_prb'])\nxg_prd_df= xg_prd_df.rename(columns = {l:'xg_'+atks[l] for l in range(len(atks))})\n\ndf = pd.concat([rd_prd_df, xg_prd_df], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params={\"C\":np.logspace(-7,7,7), \"penalty\":[\"l2\"], \"multi_class\":['auto','ovr']}\nlg = LogisticRegression(C=4.5, random_state = 42, multi_class = 'ovr', solver = 'lbfgs', max_iter = 1000)\nclf = GridSearchCV(lg, params, cv=3)\nclf.fit(df[:20000], Y[:20000])\nprint(\"训练准确率：\", clf.score(df[:20000], Y[:20000]))\nprint(\"测试准确率：\",clf.score(df[20000:], Y[20000:]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}